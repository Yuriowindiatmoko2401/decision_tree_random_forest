{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penjelasan akan dimulai dan langsung diilustrasikan dengan simulasi model terhadap data dengan tiga fitur (independent variable) yaitu \"Refund\" , \"Marital Status\" , \"Taxable Income\" dan \"Cheat\" sebagai output (dependent variable) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contoh 1 model decision tree\n",
    "\n",
    " - urutan atribut : refund --> marital status --> Tax Income\n",
    "\n",
    "<img src=\"dt_1.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contoh 2 model decision tree\n",
    "\n",
    "- urutan atribut : marital status --> refund --> Tax Income\n",
    "\n",
    "<img src=\"dt_2.png\" width=\"80%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aplikasi model 1 dengan data test baru\n",
    "\n",
    "<img src=\"tes_data_1.png\" width=\"80%\">\n",
    "\n",
    "jawaban\n",
    "\n",
    "<img src=\"tes_data_2.png\" width=\"80%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Induction (induksi pohon) metode penentuan splitting pohon\n",
    "\n",
    "- Strategi Greedy. \n",
    "    - memisahkan catatan (atribut-atribut dari salah satu fitur) berdasarkan uji atribut yang mengoptimalkan kriteria tertentu.\n",
    "\n",
    "- Masalah / isu \n",
    "    - Menentukan cara membagi catatan \n",
    "      - Bagaimana menentukan kondisi pengujian atribut? \n",
    "      - Bagaimana cara menentukan split terbaik? \n",
    "    - Menentukan kapan harus berhenti splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagaimana Cara Menentukan Kondisi Pengujian atribut?\n",
    " \n",
    "Bergantung pada tipe atribut \n",
    " - Nominal (kategori)\n",
    " - Ordinal (kategori tingkatan)\n",
    " - Bilangan Continuous\n",
    "\n",
    "Bergantung pada sejumlah cara untuk splitting \n",
    "- Perpecahan 2 arah (2-way split)\n",
    "- Perpecahan multi-arah (multi-way split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Berdasarkan Attributes Nominal \n",
    "\n",
    " - Splitting multi-arah: menggunakan sebanyak mungkin partisi atribut sebagai nilai yang berbeda\n",
    " \n",
    " <img src=\"multi-way.png\" width=\"80%\">\n",
    " \n",
    " - Spliting Biner (2-arah): Membagi nilai menjadi dua himpunan bagian. Perlu mencari partisi yang optimal.\n",
    " \n",
    " <img src=\"binary-way2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Berdasarkan Attributes Ordinal \n",
    "\n",
    " - Splitting multi-arah: menggunakan sebanyak mungkin partisi atribut sebagai nilai yang berbeda\n",
    " \n",
    " <img src=\"multi-way_2.png\" width=\"80%\">\n",
    " \n",
    " - Spliting Biner (2-arah): Membagi nilai menjadi dua himpunan bagian. Perlu mencari partisi yang optimal.\n",
    " \n",
    " <img src=\"binary_way_2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Berdasarkan Attributes Continuous\n",
    "     \n",
    "- Berbagai cara penanganan \n",
    "    - Diskritisasi untuk membentuk atribut kategori ordinal \n",
    "        - Statis - mendiskritkan sekali di awal \n",
    "        - Rentang dinamis dapat ditemukan dengan bucket interval yang sama, bucketing frekuensi yang sama (persentil), atau pengelompokan. \n",
    "    - Keputusan Biner: (A < v) atau (A >= v) \n",
    "        - pertimbangkan semua kemungkinan splitting dan temukan potongan terbaik \n",
    "        - Dapat lebih banyak hitungan secara intensif untuk mendapatkan potongan terbaik\n",
    "\n",
    "<img src=\"splitting_continuous.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagaimana cara menentukan split terbaik\n",
    "\n",
    "misal:\n",
    "\n",
    "Sebelum splitting: \n",
    "- 10 catatan kelas 0 ,\n",
    "- 10 catatan kelas 1 \n",
    "\n",
    "<img src=\"determine_best_split.png\" width=\"80%\">\n",
    "\n",
    "<img src=\"determine_best_split_1.png\" width=\"80%\">\n",
    "\n",
    "Greedy approach: \n",
    "Nodes with homogeneous class distribution are preferred\n",
    "Need a measure of node impurity:\n",
    "\n",
    "- Pendekatan Greedy (serakah):\n",
    "    - Simpul dengan distribusi kelas homogen lebih diutamakan\n",
    "- Butuh pengukuran dari ketidakmurnian simpul:\n",
    "\n",
    "<img src=\"impurity_measure.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pengukuran Ketidakmurnian simpul \n",
    "- Indeks Gini \n",
    "- Entropi\n",
    "- error dari kesalahan klasifikasi\n",
    "\n",
    "Cara menemukan splitting terbaik\n",
    "\n",
    "<img src=\"gini_index.png\" width=\"80%\"><br />\n",
    "<center>gain(didapatkan)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pengukuran Ketidaksempurnaan simpul : GINI\n",
    "\n",
    "Indeks Gini untuk simpul (t) :\n",
    "\n",
    "<img src=\"gini_formula.png\" width=\"50%\">\n",
    "\n",
    "(notes: p (j | t) adalah frekuensi relatif kelas j pada simpul t).\n",
    "\n",
    "Maksimum (1 - 1 / nc) ketika catatan didistribusikan secara merata di antara semua kelas, menyiratkan informasi yang paling tidak menarik \n",
    "Minimum (0,0) ketika semua catatan milik satu kelas, menyiratkan informasi paling menarik\n",
    "[dokumentasi referensi](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity)\n",
    "\n",
    "<img src=\"gini_index1.png\" width=\"80%\">\n",
    "\n",
    "### cara menghitung GINI\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>Kelas</th>\n",
    "    <th>Frekuensi</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C1</td>\n",
    "    <td>0</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C2</td>\n",
    "    <td>6</td> \n",
    "  </tr>\n",
    "</table>\n",
    "- P(C1) = 0/6 = 0   <-->   P(C2) = 6/6 = 1\n",
    "- Gini = 1 - P(C1)^2  - P(C2)^2 = 1 - 0 - 1 = 0\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>Kelas</th>\n",
    "    <th>Frekuensi</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C1</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C2</td>\n",
    "    <td>5</td> \n",
    "  </tr>\n",
    "</table>\n",
    "- P(C1) = 1/6    <-->   P(C2) = 5/6 \n",
    "- Gini = 1 - P(C1)^2  - P(C2)^2 = 1 - (1/6)^2 - (5/6)^2 = 0.278\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>Kelas</th>\n",
    "    <th>Frekuensi</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C1</td>\n",
    "    <td>2</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>C2</td>\n",
    "    <td>4</td> \n",
    "  </tr>\n",
    "</table>\n",
    "- P(C1) = 2/6   <-->   P(C2) = 4/6\n",
    "- Gini = 1 - P(C1)^2  - P(C2)^2 = 1 - (2/6)^2 - (4/6)^2 = 0.444\n",
    "\n",
    "### Splitting berdasakan GINI\n",
    "                \n",
    "- Menggunakan CART, SLIQ, SPRINT.\n",
    "- Ketika sebuah simpul p dibagi (di split) menjadi partisi k (anak cabang), kualitas splitting dihitung sebagai,\n",
    "\n",
    "<img src=\"gini_formula_2.png\" width=\"80%\">\n",
    "\n",
    "dimana, \n",
    "- ni = jumlah catatan di cabang anak i,\n",
    "- n = jumlah catatan di node (simpul) p (parent / induk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atribut Biner (2 arah) : menghitung Gini Index\n",
    "\n",
    "- Split menjadi 2 partisi \n",
    "- Efek dari Pembobotan Partisi :\n",
    "    - Partisi yang lebih besar dan paling murni lah yang dicari\n",
    "    \n",
    "<img src=\"atribut_biner_1.png\" width=\"30%\">\n",
    "\n",
    "<img src=\"node_parent.png\" width=\"30%\">\n",
    "\n",
    "<img src=\"node_child.png\" width=\"30%\">\n",
    "\n",
    "- Gini(N1) \n",
    "- = 1 – (5/6)^2 – (2/6)^2 \n",
    "- = 0.194 \n",
    "\n",
    "\n",
    "- Gini(N2) \n",
    "- = 1 – (1/6)^2 – (4/6)^2 \n",
    "- = 0.528\n",
    "\n",
    "\n",
    "- Gini(anak cabang / child) \n",
    "- = 7/12 * 0.194 + \n",
    "   5/12 * 0.528\n",
    "- = 0.333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atribut Kategori : Menghitung Indeks Gini\n",
    "\n",
    "- Untuk setiap nilai berbeda, hitung jumlah untuk setiap kelas dalam kumpulan data\n",
    "- Gunakan matriks hitungan untuk membuat keputusan\n",
    "\n",
    "<img src=\"atribut_kategori.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gini(N1) \n",
    "- = 1 – (1/10/3)^2 – (4/10/3)^2 \n",
    "- = 1 - 9/100 - 144/100 = -53/100\n",
    "\n",
    "\n",
    "- Gini(N2) \n",
    "- = 1 – (2/10/3)^2 – (1/10/3)^2 \n",
    "- = 1 - 36/100 - 9/100 = 55/100\n",
    "\n",
    "\n",
    "- Gini(N3) \n",
    "- = 1 – (1/10/3)^2 – (1/10/3)^2 \n",
    "- = 1 - 9/100 - 9/100 = 82/100\n",
    "\n",
    "\n",
    "- Gini(anak cabang / child) \n",
    "- = 5/10 * -53/100 + \n",
    "   3/10 * 55/100 + 2/10 * 82/100 \n",
    "- = 0.064   (??= (0.333)??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yurio/anaconda/envs/eml/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Load irisdewfre dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Instantiate\n",
    "iris = load_iris()\n",
    "\n",
    "# Create training and feature\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/yurio/anaconda/envs/eml/lib/python3.6/site-packages/sklearn/cross_validation.py:41: peringatan penyangkalan: Modul ini tidak lagi digunakan di versi 0.18 yang mendukung modul model_selection di mana semua kelas refactored dan fungsi dipindahkan. Perhatikan juga bahwa antarmuka iterator CV yang baru berbeda dari antarmuka modul ini. Modul ini akan dihapus dalam 0,20. \"Modul ini akan dihapus dalam 0,20.\", peringatan penyangkalan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8, 2.8, 5.1, 2.4],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [6. , 2.7, 5.1, 1.6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
    " 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
    " 'feature_names': ['sepal length (cm)',\n",
    "  'sepal width (cm)',\n",
    "  'petal length (cm)',\n",
    "  'petal width (cm)']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train dataset 1.0\n",
      "accuracy on test dataset 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Instantiate\n",
    "# default criterion=gini\n",
    "# you can swap to criterion=entropy\n",
    "dtc = DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "\n",
    "# 2. Fit\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict, there're 4 features in the irisdewfre dataset\n",
    "y_test_pred_class = dtc.predict(X_test)\n",
    "y_train_pred_class = dtc.predict(X_train)\n",
    "\n",
    "result_test=metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "result_train=metrics.accuracy_score(y_train, y_train_pred_class)\n",
    "\n",
    "print('accuracy on train dataset', result_train)\n",
    "print('accuracy on test dataset', result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        dtc,\n",
    "        out_file=image_path(\"iris_tree_deui.dot\"),\n",
    "        feature_names=iris.feature_names,\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !dot -Tpng \"images/decision_trees/iris_tree_deui.dot\" -o iris_tree_deui.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mpimg.imread(\"images/decision_trees/iris_tree_deui.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/decision_trees/iris_tree_deui.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Load irisdewfre dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Instantiate\n",
    "iris = load_iris()\n",
    "\n",
    "# Create training and feature\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train dataset 0.9910714285714286\n",
      "accuracy on test dataset 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=2, random_state=0, n_estimators=5)\n",
    "\n",
    "# 2. Fit\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict, there're 4 features in the irisdewfre dataset\n",
    "y_test_pred_class = rfc.predict(X_test)\n",
    "y_train_pred_class = rfc.predict(X_train)\n",
    "\n",
    "result_test=metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "result_train=metrics.accuracy_score(y_train, y_train_pred_class)\n",
    "\n",
    "print('accuracy on train dataset', result_train)\n",
    "print('accuracy on test dataset', result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euro Banknotes Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, percentfortrain):\n",
    "    data=np.genfromtxt(filename, delimiter=',')\n",
    "    size=len(data)\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    for i in range(size):\n",
    "        x_data = data[i][0:4]\n",
    "        y_data = data[i][4]\n",
    "        rn=random.random()\n",
    "        if rn<percentfortrain:\n",
    "            #train\n",
    "             x_train.append(x_data)\n",
    "             y_train.append(y_data)\n",
    "\n",
    "            #for j in range(0, 3):\n",
    "            #    x_train.append(data[i])\n",
    "\n",
    "        else:\n",
    "            #test\n",
    "            x_test.append(x_data)\n",
    "            y_test.append(y_data)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "x_train, y_train, x_test, y_test=load_data('data_banknote_authentication.csv', 0.75)\n",
    "\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Create actual english names for the plants for each predicted plant class\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========features importances=====================\n",
      "[0.58396319 0.20670074 0.16244545 0.04689062]\n",
      "accuracy_train 1.0\n",
      "accuracy_test 0.9911504424778761\n"
     ]
    }
   ],
   "source": [
    "print ('========features importances=====================')\n",
    "# Create confusion matrix\n",
    "# View a list of the features and their importance scores\n",
    "print (clf.feature_importances_)\n",
    "\n",
    "accuracy_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "print ('accuracy_train',accuracy_train)\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print ('accuracy_test',accuracy_test)\n",
    "\n",
    "# save to file\n",
    "with open('randomforest_model.mdl', 'wb') as output:\n",
    "    pickle.dump(clf, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "#import random\n",
    "#from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "newdata=[[3.6216,8.6661,-2.8073,-0.44699],\n",
    "         [4.5459,8.1674,-2.4586,-1.4621],\n",
    "         [-3.5637,-8.3827,12.393,-1.2823],\n",
    "         [-2.5419,-0.65804,2.6842,1.1952]\n",
    "]\n",
    "objectfile = open(\"randomforest_model.mdl\",'rb')\n",
    "clf=pickle.load(objectfile)\n",
    "\n",
    "# Create actual english names for the plants for each predicted plant class\n",
    "pred = clf.predict(newdata)\n",
    "\n",
    "print (pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
